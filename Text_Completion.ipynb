{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import string\n",
    "\n",
    "#Uncomment below lines if running first time!!\n",
    "#nltk.download()\n",
    "#nltk.download('punkt')\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Emma by Jane Austen 1816 \n"
     ]
    }
   ],
   "source": [
    "austen = gutenberg.sents('austen-emma.txt') # can choose another auther name from the available choices\n",
    "\n",
    "#To remove the punctuation\n",
    "punctRemover=str.maketrans('','',string.punctuation)\n",
    "innerStr = \" \"\n",
    "strToAppend= \" \"\n",
    "X_austen = [] \n",
    "for row in austen:\n",
    "    if row:\n",
    "        innerStr = ' '.join([str(elem) for elem in row])\n",
    "        wordlist = innerStr.split(' ')\n",
    "        strToAppend = ' '.join([str(word) for word in wordlist]) #convert the list to single string\n",
    "        X_austen.append(strToAppend.translate(punctRemover))\n",
    "        \n",
    "print(X_austen[0]) #Print first entry of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'by', 'jane', 'austen', '1816']\n"
     ]
    }
   ],
   "source": [
    "token_austen = []\n",
    "for item in X_austen:\n",
    "    tokenTemp = word_tokenize((str(item)).lower())\n",
    "    token_austen.append(tokenTemp)\n",
    "    \n",
    "print(token_austen[0]) #print tokenized list's first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Vocabulary\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "#padded_everygram_pipeline: this is equivalent to doing left and right padding and then creating bigrams and vocabulary\n",
    "#train_austen: contains the bigrams of text of author Austen\n",
    "#vocab_austen: cantains the single list of all the words present in Austen text \n",
    "train_austen, vocab_austen = padded_everygram_pipeline(2, token_austen) # input 2 will create model equivalent to bigram\n",
    "\n",
    "#For handling the unknown terms a token label '<UNK>' is added in the vocabulary by using function vocabulary\n",
    "#unk_cutoff: tells if a words appears less then 'unk_cutoff' times, then consider it unknown\n",
    "vocabFinal_austen = Vocabulary(vocab_austen, unk_cutoff=1, unk_label='<UNK>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "model_austen = MLE(2)   #Choosing Maximum likelihood estimation model. The input 2 is the ngram order\n",
    "model_austen.fit(train_austen, vocabFinal_austen) # fitting the model from bigrams and vocabulary generated in Q5(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction for Austen:\n",
      "i do them baked apples from intellectual solitude for me\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer # for using detokenize to combine generated token into a sentence\n",
    "\n",
    "print(\"\\nPrediction for Austen:\")\n",
    "#num_words: number of words to be generated\n",
    "#text_seed: A word is sent as text seed. The generation will be done considereing it as the preceeded word\n",
    "print(TreebankWordDetokenizer().detokenize(model_austen.generate(num_words=10, text_seed='she', random_seed= None)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
